- Collect more 2d approaches
- explain how 2d approaches handle large datasets
- propose a solution for 3d based on papers and existing research
- write java code for it    

intermediate format will be necessary BFF ðŸ’–
different model sizes + parameter + weights file
try out uniform feature extractors

test on empty data
test with noise data
off voxelization for empty/full chunks? skip them completely?

caching at while scanning would be nice but in practice it does not work
todo:
  collect bounding boxes in persistentlist to support very large files

intro - high level
repository structure
speicherung auf disk


cleanup
tutorial
readme
documentation

einleitung
  thema hinfuehren
  ki grossteils bildbasiert
  3d nix
  3d problematisch

related work
  background
  yolo
  input output
  begriffserklaerungen

mein teil
  was ich gebaut habe
  ergebisse
  einzelne ergebnisse qualitativ

evaluierung bewertung
  funktionalitat
  lessons learned - bottlenecks
  future work


RELATED WORK
yolo: https://arxiv.org/abs/1506.02640
yolo2: https://arxiv.org/abs/1612.08242
yolo3: https://arxiv.org/abs/1804.02767
yolo4: https://arxiv.org/abs/2004.10934

intro
  For 2d contexts, amazing solutions exist
  lots of different approaches, for different use-cases
  one of them is yolo
  elegant, simple, fast


mein teil
  the work in this paper is mostly focused on providing the ability to process large files
  the accuracy of the detection is of secondary priority
    the reason is: there are many detection networks one could use to achive this task
    as an example the yolo network was adapted and used here

  input for a neural network needs to be in the form of a tensor multiple representations are possible
  in this context the most useful is a voxel based interpretations
  input for the network is a 4 dimensional tensor. 3 spacial dimensions x,y,z and an additional dimension to support multiple channels (r,g,b etc)
  to force the network to detect the shape of an object only one dimension is used. otherwise it could use the color of an object to figure out what it is
  technically the input could also be seen as 5 dimensional with the fifth dimension being the batch-size. this means that the model can process multiple inputs at the same time

  + visual representation of the input tensor

  another problem is the sheer size of the models that need to be processed
  larger network input shapes mean more context for detection aka larger features can be detected but they also make the network slower
  and smaller features may be interpreted as noise
  therefore this framework supports networks of any size to detect features. The actual size should be chose based on the use case at hand
  of course you could also scan the input data at different resolutions by skipping every other sample value as well

  the approach taken in this paper is similar to a convolutional neural network.
  we slide a window over the input file to scan small sections at a time 
  we then collect the partial results and store them for later evaluation




NEW QUESTIONS:

- How many images are okay in a thesis?